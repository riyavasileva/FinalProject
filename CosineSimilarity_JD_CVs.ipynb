{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Resumes to Jobs using Cosine Similarity "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way how we can compare CVs to job description is through vectorization and cosine similariy. \n",
    "\n",
    "\"Cosine similarity considers cosine angle between them and converts it to a similarity score between 0 to 100 percent.\"\n",
    "\n",
    "<b> Sources: </b>\n",
    "- https://www.machinelearningplus.com/nlp/cosine-similarity/\n",
    "- https://chatbotslife.com/ranking-resumes-for-a-given-job-description-using-natural-language-processing-a-toy-project-1f49d3156b44"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are adding job description for a Data Analyst role (https://careers.getyourguide.com/positions/engineering/data-analyst-business-analytics/berlin/) and 10 CVs. All files should be present in github. \n",
    "\n",
    "Note: files are already pre-processed in separate notebooks (present in github). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a Data Analyst, you will help drive measurement, strategy, and tactical decision-making within GetYourGuide. You will solve problems that could range from forecasting the ticket sales of our some of our key attractions, analyzing the success of our new product features, help develop strategies to improve customer service experience, or help our sales team decide which tours to acquire.\n",
      "\n",
      "\n",
      "\n",
      "Responsibilities:\n",
      "\n",
      "\n",
      "\n",
      "Develop quantitative analysis to drive business & product decisions\n",
      "\n",
      "Explore large datasets, give meaning to data and numbers, identify opportunities and issues, and present findings to stakeholders\n",
      "\n",
      "Deliver analysis, insights, and recommendations to business teams to make impactful decisions\n",
      "\n",
      "Design and implement metrics, dashboards, and reports\n",
      "\n",
      "Serve as a liaison between the business teams and the data engineering team \n",
      "\n",
      "Requirements: \n",
      "\n",
      "\n",
      "\n",
      "2-3 years of relevant experience interpreting data in an analytics, data science or business intelligence role\n",
      "\n",
      "Strong knowledge of SQL \n",
      "\n",
      "Experience with data visualization and reporting tools (e.g. Looker, Jupyter Notebooks)\n",
      "\n",
      "Curiosity, reasoning skills with proven evidence of problem solving.\n",
      "\n",
      "Ability to understand user behavior and meaning behind the numbers\n",
      "\n",
      "Desire to work in an international environment, with minimal direction and with highly engaged individuals\n",
      "\n",
      "Great communication skills\n",
      "\n",
      "Nice to have:\n",
      "\n",
      "\n",
      "\n",
      "Experience in business analytics/strategy is a plus\n",
      "\n",
      "Demonstrated ability to understand the business of a tech company\n",
      "\n",
      "Familiarity with statistical packages (e.g. R, Python)\n",
      "\n",
      "Experience with big data tools (e.g. Spark, Hive) is a plus\n"
     ]
    }
   ],
   "source": [
    "#loading the job description\n",
    "jd=docx2txt.process(\"Data Analyst_JD.docx\")\n",
    "print(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading CVs (note: I did it here quite manually, at the end I tried to clean it with for loops..was not able to finish it though)\n",
    "CV1=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 1.docx\")\n",
    "CV2=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 2.docx\")\n",
    "CV3=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 3.docx\")\n",
    "CV4=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 4.docx\")\n",
    "CV5=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 5.docx\")\n",
    "CV6=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 6.docx\")\n",
    "CV7=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 7.docx\")\n",
    "CV8=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 8.docx\")\n",
    "CV9=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 9.docx\")\n",
    "CV10=docx2txt.process(\"/Users/riyavasileva/Ironhack/Final Project/CV_Project/CV 10.docx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating lists of respective CV + job description\n",
    "group1 = [CV1, jd]\n",
    "group2 = [CV2, jd]\n",
    "group3 = [CV3, jd]\n",
    "group4 = [CV4, jd]\n",
    "group5 = [CV5, jd]\n",
    "group6 = [CV6, jd]\n",
    "group7 = [CV7, jd]\n",
    "group8 = [CV8, jd]\n",
    "group9 = [CV9, jd]\n",
    "group10 = [CV10, jd]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizing the lists (note to self: you can also use tf-idf)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "count_matrix1 = cv.fit_transform(group1)\n",
    "count_matrix2 = cv.fit_transform(group2)\n",
    "count_matrix3 = cv.fit_transform(group3)\n",
    "count_matrix4 = cv.fit_transform(group4)\n",
    "count_matrix5 = cv.fit_transform(group5)\n",
    "count_matrix6 = cv.fit_transform(group6)\n",
    "count_matrix7 = cv.fit_transform(group7)\n",
    "count_matrix8 = cv.fit_transform(group8)\n",
    "count_matrix9 = cv.fit_transform(group9)\n",
    "count_matrix10 = cv.fit_transform(group10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Similarity Scores of CVs and job descriptions are as follows:\n",
      "[[1.        0.5391479]\n",
      " [0.5391479 1.       ]]\n",
      "[[1.         0.54142034]\n",
      " [0.54142034 1.        ]]\n",
      "[[1.         0.46276808]\n",
      " [0.46276808 1.        ]]\n",
      "[[1.         0.48819259]\n",
      " [0.48819259 1.        ]]\n",
      "[[1.         0.35617263]\n",
      " [0.35617263 1.        ]]\n",
      "[[1.         0.59722369]\n",
      " [0.59722369 1.        ]]\n",
      "[[1.         0.59373997]\n",
      " [0.59373997 1.        ]]\n",
      "[[1.         0.56684298]\n",
      " [0.56684298 1.        ]]\n",
      "[[1.         0.45461117]\n",
      " [0.45461117 1.        ]]\n",
      "[[1.         0.53495062]\n",
      " [0.53495062 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "#printing the cousine similarity scores\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"\\nSimilarity Scores of CVs and job descriptions are as follows:\")\n",
    "print(cosine_similarity(count_matrix1))\n",
    "print(cosine_similarity(count_matrix2))\n",
    "print(cosine_similarity(count_matrix3))\n",
    "print(cosine_similarity(count_matrix4))\n",
    "print(cosine_similarity(count_matrix5))\n",
    "print(cosine_similarity(count_matrix6))\n",
    "print(cosine_similarity(count_matrix7))\n",
    "print(cosine_similarity(count_matrix8))\n",
    "print(cosine_similarity(count_matrix9))\n",
    "print(cosine_similarity(count_matrix10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV1 matches 53.91% of the job description.\n",
      "CV2 matches 54.14% of the job description.\n",
      "CV3 matches 46.28% of the job description.\n",
      "CV4 matches 48.82% of the job description.\n",
      "CV5 matches 35.62% of the job description.\n",
      "CV6 matches 59.72% of the job description.\n",
      "CV7 matches 59.37% of the job description.\n",
      "CV8 matches 56.68% of the job description.\n",
      "CV9 matches 45.46% of the job description.\n",
      "CV10 matches 53.5% of the job description.\n"
     ]
    }
   ],
   "source": [
    "#turn the outcome into %s\n",
    "matchPercentage1 = cosine_similarity(count_matrix1)[0][1] * 100\n",
    "matchPercentage1 = round(matchPercentage1, 2) # rounding decimals\n",
    "print(\"CV1 matches \"+ str(matchPercentage1)+ \"% of the job description.\")\n",
    "\n",
    "matchPercentage2 = cosine_similarity(count_matrix2)[0][1] * 100\n",
    "matchPercentage2 = round(matchPercentage2, 2) # rounding decimals\n",
    "print(\"CV2 matches \"+ str(matchPercentage2)+ \"% of the job description.\")\n",
    "\n",
    "matchPercentage3 = cosine_similarity(count_matrix3)[0][1] * 100\n",
    "matchPercentage3 = round(matchPercentage3, 2) # rounding decimals\n",
    "print(\"CV3 matches \"+ str(matchPercentage3)+ \"% of the job description.\")\n",
    "\n",
    "matchPercentage4 = cosine_similarity(count_matrix4)[0][1] * 100\n",
    "matchPercentage4 = round(matchPercentage4, 2) # rounding decimals\n",
    "print(\"CV4 matches \"+ str(matchPercentage4)+ \"% of the job description.\")\n",
    "\n",
    "matchPercentage5 = cosine_similarity(count_matrix5)[0][1] * 100\n",
    "matchPercentage5 = round(matchPercentage5, 2) # rounding decimals\n",
    "print(\"CV5 matches \"+ str(matchPercentage5)+ \"% of the job description.\")\n",
    "\n",
    "matchPercentage6 = cosine_similarity(count_matrix6)[0][1] * 100\n",
    "matchPercentage6 = round(matchPercentage6, 2) # rounding decimals\n",
    "print(\"CV6 matches \"+ str(matchPercentage6)+ \"% of the job description.\")\n",
    "\n",
    "matchPercentage7 = cosine_similarity(count_matrix7)[0][1] * 100\n",
    "matchPercentage7 = round(matchPercentage7, 2) # rounding decimals\n",
    "print(\"CV7 matches \"+ str(matchPercentage7)+ \"% of the job description.\")\n",
    "\n",
    "matchPercentage8 = cosine_similarity(count_matrix8)[0][1] * 100\n",
    "matchPercentage8 = round(matchPercentage8, 2) # rounding decimals\n",
    "print(\"CV8 matches \"+ str(matchPercentage8)+ \"% of the job description.\")\n",
    "\n",
    "matchPercentage9 = cosine_similarity(count_matrix9)[0][1] * 100\n",
    "matchPercentage9 = round(matchPercentage9, 2) # rounding decimals\n",
    "print(\"CV9 matches \"+ str(matchPercentage9)+ \"% of the job description.\")\n",
    "\n",
    "matchPercentage10 = cosine_similarity(count_matrix10)[0][1] * 100\n",
    "matchPercentage10 = round(matchPercentage10, 2) # rounding decimals\n",
    "print(\"CV10 matches \"+ str(matchPercentage10)+ \"% of the job description.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code smarter.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above is not very efficient if we have more than 10 resumes (as usually you do have). Hence, we need to create for loops and functions. \n",
    "\n",
    "Note: there are 30 CVs in the folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from docx import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/riyavasileva/Ironhack/Final Project/CV_Project/' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for file in os.listdir(path):\n",
    "    if file.endswith('.docx'):\n",
    "        files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CV 1.docx',\n",
       " 'CV 2.docx',\n",
       " 'CV 3.docx',\n",
       " 'CV 4.docx',\n",
       " 'CV 5.docx',\n",
       " 'CV 6.docx',\n",
       " 'CV 7.docx',\n",
       " 'CV 8.docx',\n",
       " 'CV 9.docx',\n",
       " 'CV 10.docx',\n",
       " 'CV 11.docx',\n",
       " 'CV 12.docx',\n",
       " 'CV 13.docx',\n",
       " 'CV 14.docx',\n",
       " 'CV 15.docx',\n",
       " 'CV 16.docx',\n",
       " 'CV 17.docx',\n",
       " 'CV 18.docx',\n",
       " 'CV 19.docx',\n",
       " 'CV 20.docx',\n",
       " 'CV 21.docx',\n",
       " 'CV 22.docx',\n",
       " 'CV 23.docx',\n",
       " 'CV 24.docx',\n",
       " 'CV 25.docx',\n",
       " 'CV 26.docx',\n",
       " 'CV 27.docx',\n",
       " 'CV 28.docx',\n",
       " 'CV 29.docx',\n",
       " 'CV 31.docx']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#showing files alphabetically\n",
    "import re\n",
    "files.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the text files in a dictionary\n",
    "files_dct = {}\n",
    "for file in files:\n",
    "    full_path = os.path.join(path,file)\n",
    "    text = docx2txt.process(file)\n",
    "    files_dct[\"CV%s\" %file] = text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(files_dct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "files_dct['CVCV 4.docx']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note: </b> I will need to further increase the usability of the code, and make it better. This will take place during the Xmas break :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
